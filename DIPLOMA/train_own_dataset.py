import os
import json
from collections import Counter

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler
from PIL import Image

# --- –ì—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏ ---
BATCH_SIZE = 32
EPOCHS = 10
LEARNING_RATE = 0.001
MODEL_PATH = "resnet50_custom.pth"

# --- –í–∏–∑–Ω–∞—á–∞—î–º–æ, —á–∏ –¥–æ—Å—Ç—É–ø–Ω–∏–π GPU ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó ---
transform = transforms.Compose([
    transforms.Resize((32, 32)),  # –ó–º—ñ–Ω—é—î–º–æ —Ä–æ–∑–º—ñ—Ä –¥–ª—è ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
])


# --- –ö–∞—Å—Ç–æ–º–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç, —è–∫–∏–π –æ–±—Ä–æ–±–ª—è—î –≤—Å—ñ –ø—ñ–¥–ø–∞–ø–∫–∏ ---
class CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.annotations = []
        self.class_to_idx = {}  # –î–ª—è –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞–∑–≤ –∫–ª–∞—Å—ñ–≤ —É —á–∏—Å–ª–æ–≤—ñ —ñ–Ω–¥–µ–∫—Å–∏

        # --- –ó—á–∏—Ç—É—î–º–æ –≤—Å—ñ –ø—ñ–¥–ø–∞–ø–∫–∏ —É dataset ---
        for class_idx, class_name in enumerate(os.listdir(root_dir)):
            class_path = os.path.join(root_dir, class_name)
            annotation_path = os.path.join(class_path, "annotations.json")

            if not os.path.isdir(class_path) or not os.path.exists(annotation_path):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ, —è–∫—â–æ —Ü–µ –Ω–µ –ø–∞–ø–∫–∞ –∞–±–æ –Ω–µ–º–∞—î –∞–Ω–æ—Ç–∞—Ü—ñ–π

            # --- –î–æ–¥–∞—î–º–æ –∫–ª–∞—Å —É —Å–ª–æ–≤–Ω–∏–∫ ---
            self.class_to_idx[class_name] = class_idx

            # --- –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞–Ω–æ—Ç–∞—Ü—ñ—ó ---
            with open(annotation_path, "r") as f:
                annotations = json.load(f)

            for ann in annotations:
                img_path = os.path.join(class_path, ann["image"])
                self.annotations.append({"img_path": ann["image"], "label": class_idx})

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        ann = self.annotations[idx]
        image = Image.open(ann["img_path"]).convert("RGB")
        label = ann["label"]  # –Ü–Ω–¥–µ–∫—Å –∫–ª–∞—Å—É

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(label, dtype=torch.long)


# --- –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞—Ç–∞—Å–µ—Ç ---
dataset_path = "dataset"
dataset = CustomDataset(root_dir=dataset_path, transform=transform)

# --- –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –ø—É—Å—Ç–∏–π ---
if len(dataset) == 0:
    raise ValueError("‚ùå –ü–æ–º–∏–ª–∫–∞: –¥–∞—Ç–∞—Å–µ—Ç –ø–æ—Ä–æ–∂–Ω—ñ–π. –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ –¥–∞–Ω—ñ –∫–æ—Ä–µ–∫—Ç–Ω—ñ.")


# --- –°—Ç–≤–æ—Ä—é—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ—ó —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ—ó –≤–∏–±—ñ—Ä–∫–∏ ---
indices = list(range(len(dataset)))
train_indices, val_indices = train_test_split(indices, test_size=0.2, stratify=[dataset[idx][1].item() for idx in indices])

train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)

train_labels = [dataset[idx][1].item() for idx in train_indices]
val_labels = [dataset[idx][1].item() for idx in val_indices]

print("–†–æ–∑–ø–æ–¥—ñ–ª —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤:", Counter(train_labels))
print("–†–æ–∑–ø–æ–¥—ñ–ª –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤:", Counter(val_labels))


# --- –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—á—ñ –¥–∞–Ω–∏—Ö ---
train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)
val_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)
# --- –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å ResNet-50 ---
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
num_classes = len(dataset.class_to_idx)  # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤
model.fc = nn.Linear(model.fc.in_features, num_classes)  # –û–Ω–æ–≤–ª—é—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —à–∞—Ä

model = model.to(device)

# --- –§—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä ---
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)


# --- –§—É–Ω–∫—Ü—ñ—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ---
def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct, total = 0, 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

        train_acc = correct / total * 100
        val_acc = evaluate_model(model, val_loader)
        print(
            f"üåÄ –ï–ø–æ—Ö–∞ {epoch + 1}/{epochs} | –í—Ç—Ä–∞—Ç–∞: {running_loss:.4f} | –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: {train_acc:.2f}% | –í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: {val_acc:.2f}%")

    torch.save(model.state_dict(), MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ {MODEL_PATH}")


# --- –§—É–Ω–∫—Ü—ñ—è –æ—Ü—ñ–Ω–∫–∏ ---
def evaluate_model(model, dataloader):
    model.eval()
    correct, total = 0, 0

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    accuracy = correct / total * 100
    return accuracy


# --- –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ---
if __name__ == "__main__":
    train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS)
